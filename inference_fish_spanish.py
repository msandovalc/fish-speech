import io
import os
import re
import sys
import torch
import gc
import shutil
import numpy as np
import soundfile as sf
import platform
from pathlib import Path
from loguru import logger
from datetime import datetime


# --- SYSTEM CONFIGURATION ---
logger.remove()
logger.add(sys.stdout, colorize=True, level="TRACE",
           format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{message}</cyan>")

# Performance optimization for Windows/Linux
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True,max_split_size_mb:128"

# --- CONSTANTS ---
# Auto-detect project root
PROJECT_ROOT = Path(__file__).resolve().parent

# --- IMPORTS WITH FALLBACK ---
try:
    from fish_speech.inference_engine import TTSInferenceEngine
    from fish_speech.models.dac.inference import load_model as load_decoder_model
    from fish_speech.models.text2semantic.inference import launch_thread_safe_queue
    from fish_speech.utils.schema import ServeTTSRequest, ServeReferenceAudio
    from fish_speech.utils import set_seed
except ImportError:
    # If running from a notebook cell, add root to path
    sys.path.insert(0, str(PROJECT_ROOT))
    from fish_speech.inference_engine import TTSInferenceEngine
    from fish_speech.models.dac.inference import load_model as load_decoder_model
    from fish_speech.models.text2semantic.inference import launch_thread_safe_queue
    from fish_speech.utils.schema import ServeTTSRequest, ServeReferenceAudio
    from fish_speech.utils import set_seed

# --- VOICE PRESETS (OPTIMIZED FOR S1-MINI) ---
# NOTE: Temperatures lowered to ~0.75 and Penalty to ~1.05 to prevent metallic artifacts.
VOICE_PRESETS = {
    # "MARLENE": {
    #     "temp": 0.65,
    #     "top_p": 0.70,
    #     "chunk": 300,
    #     "penalty": 1.035,
    #     "ref_path": str(PROJECT_ROOT / "voices" / "ElevenLabs_Marlene.mp3"),
    #     "prompt": """La mente lo es todo. La causa mental. La causa de todo -absolutamente todo- es mental, es decir,
    #     la mente es la que produce o causa todo en la vida del individuo.
    #
    #     Cuando reconozcamos, entendamos y aceptemos esta verdad, habremos dado un paso muy importante en el progreso del desarrollo.
    #
    #     Si todo es mental, este es un universo mental, donde todo funciona por medios mentales. Nosotros somos seres
    #     mentales, mentalidades buenas, perfectas y eternas.
    #
    #     La mente s√≥lo tiene una actividad, pensar. El pensamiento es todo lo de la mente lo √∫nico que somos y tenemos es
    #     pensamiento, por ello, el pensamiento es lo m√°s importante de todo.
    #     """,
    #     "style_tags": "(calm) (narrator)"
    # },
    # "MARGARITA": {
    #     "temp": 0.65,
    #     "top_p": 0.70,
    #     "chunk": 300,
    #     "penalty": 1.035,
    #     "ref_path": str(PROJECT_ROOT / "voices" / "Margarita_Navarrete.wav"),
    #     "prompt": """Mira te comparto, hicimos tres cuartos m√°s y no suelta todav√≠a el sistema y otros detallitos,
    #     pero mira lo que te quiero comentar es que s√© que suena raro, s√© que se requiere dinero para el intercambio
    #     de lo que se desea, sin embargo todo lo que decidas hacer, hazlo porque deseas hacerlo. Lo com√∫n es buscar
    #     hacerlo porque necesitas, y entonces si se empieza a hacer todo desde la necesidad, desde pues es que Magui
    #     si lo requiero para los pagos, qued√≥ bien justito ahorita, entonces te me vas a empezar a estresar m√°s. Haz
    #     las cosas porque te gusta lo que est√°s haciendo y de lo que te gusta empieza a hacer m√°s, pero porque te gusta.
    #
    #     ¬øC√≥mo voy a poder eliminar la carencia del gusto? Por eso son las l√≠neas, a m√≠ me pas√≥, te digo tiene poco
    #     que saque el cr√©dito.
    #     """,
    #     "style_tags": "(calm) (narrator)"
    # },
    "CAMILA": {
        "temp": 0.65,
        "top_p": 0.70,
        "chunk": 300,
        "penalty": 1.035, #1.035
        "ref_path": str(PROJECT_ROOT / "voices" / "cami_sodi_50_secs.mp3"),
        "prompt": """As√≠  el  ni√±o  se  enga√±a  f√°cilmente,  toma  mentiras  o  falsedades  como verdades, 
        solo porque las ve u oye, se enga√±a como un ni√±o. El ni√±o, por ejemplo, ve que el sol sale por el oriente, 
        asciende en el firmamento; est√° en el centro o cenit al mediod√≠a y continuar√° su camino hacia el poniente, 
        donde se pone u oculta, as√≠, el sol realiza dicho recorrido todos los d√≠as, y para el ni√±o que ve eso, 
        es la verdad; pero, si tuviera la base de la realidad para razonar, de que el sol, centro del sistema solar, 
        no se mueve en ese sentido, sino que es la tierra la que se mueve, aunque la apariencia sea de que es el sol 
        el que se mueve, entonces el ni√±o sabr√≠a que el mencionado movimiento del sol es una ilusi√≥n. """,
        "style_tags": "(calm)(narrator)(deep voice)" #(deep voice)
    }
    # "ROSA": {
    #     "temp": 0.65,
    #     "top_p": 0.70,
    #     "chunk": 300,
    #     "penalty": 1.035,
    #     "ref_path": str(PROJECT_ROOT / "voices" / "Elevenlabs_Rosa_Estela.wav"),
    #     "prompt": """El agua, la confianza y el miedo. Una lecci√≥n poderosa y reveladora sobre la verdadera
    #     protecci√≥n y el poder de la preparaci√≥n. Considera la profunda ense√±anza que subyace a la instrucci√≥n sobre
    #     el miedo al agua.
    #
    #     Inbuir en la mente de un ni√±o peque√±o un temor paralizante hacia la profundidad, creyendo err√≥neamente que
    #     as√≠ se le protege de un posible ahogamiento, puede parad√≥jicamente paralizarlo por completo en un momento de
    #     peligro real, impidi√©ndole reaccionar de manera efectiva para salvar su propia vida. En contraste,
    #     ense√±ar al ni√±o un amor genuino por el agua como una parte esencial y maravillosa de la naturaleza,
    #     inculcarle un respeto saludable por su poder y, lo que es crucial, dotarlo de la habilidad vital de nadar con
    #     confianza, empodera al ni√±o de una manera transformadora. Esta analog√≠a poderosa se extiende a innumerables
    #     otros temores que, con las mejores intenciones pero con resultados a menudo limitantes, se nos transmiten
    #     desde la infancia.
    #
    #     ¬øCu√°les son esas aguas profundas metaf√≥ricas que has estado evitando en tu vida por un temor arraigado,
    #     impidi√©ndote explorar nuevas oportunidades y experiencias enriquecedoras? Comparte tu profunda reflexi√≥n en
    #     los comentarios. Dale like a este video si crees firmemente en el poder de la preparaci√≥n activa y la
    #     confianza cultivada como la verdadera protecci√≥n contra los desaf√≠os de la vida, en lugar de la evitaci√≥n
    #     basada en el miedo, y s√≠gueme para explorar juntos m√°s analog√≠as reveladoras que iluminan la naturaleza del
    #     temor y el camino hacia la liberaci√≥n.""" ,
    #     "style_tags": "(calm) (narrator) (relaxed)" #(deep voice)
    # }
    # "ALEJANDRO": {
    #     "temp": 0.65,
    #     "top_p": 0.70,
    #     "chunk": 300,
    #     "penalty": 1.035,
    #     "ref_path": str(PROJECT_ROOT / "voices" / "ElevenLabs_Alejandro.mp3"),
    #     "prompt": """(serious) (calm) La mente lo es todo. La causa mental. La causa de todo -absolutamente todo- es mental, es decir,
    #         la mente es la que produce o causa todo en la vida del individuo.
    #         Cuando reconozcamos, entendamos y aceptemos esta verdad, habremos dado un paso muy importante en el progreso del desarrollo.
    #         Si todo es mental, este es un universo mental, donde todo funciona por medios mentales. Nosotros somos seres
    #         mentales, mentalidades buenas, perfectas y eternas.
    #         La mente s√≥lo tiene una actividad, pensar. El pensamiento es todo lo de la mente lo √∫nico que somos y tenemos es
    #         pensamiento, por ello, el pensamiento es lo m√°s importante de todo.""",
    #     "style_tags": "(calm) (narrator)"
    # },
    # "ALEJANDRO_BALLESTEROS": {
    #     "temp": 0.65,
    #     "top_p": 0.70,
    #     "chunk": 300,
    #     "penalty": 1.035,
    #     "ref_path": str(PROJECT_ROOT / "voices" / "Elevenlabs_Alejandro_Ballesteros.wav"),
    #     "prompt": """El agua, la confianza y el miedo. Una lecci√≥n poderosa y reveladora sobre la verdadera
    #     protecci√≥n y el poder de la preparaci√≥n. Considera la profunda ense√±anza que subyace a la instrucci√≥n sobre
    #     el miedo al agua.
    #
    #     Inbuir en la mente de un ni√±o peque√±o un temor paralizante hacia la profundidad, creyendo err√≥neamente que
    #     as√≠ se le protege de un posible ahogamiento, puede parad√≥jicamente paralizarlo por completo en un momento de
    #     peligro real, impidi√©ndole reaccionar de manera efectiva para salvar su propia vida. En contraste,
    #     ense√±ar al ni√±o un amor genuino por el agua como una parte esencial y maravillosa de la naturaleza,
    #     inculcarle un respeto saludable por su poder y, lo que es crucial, dotarlo de la habilidad vital de nadar con
    #     confianza, empodera al ni√±o de una manera transformadora. Esta analog√≠a poderosa se extiende a innumerables
    #     otros temores que, con las mejores intenciones pero con resultados a menudo limitantes, se nos transmiten
    #     desde la infancia.
    #
    #     ¬øCu√°les son esas aguas profundas metaf√≥ricas que has estado evitando en tu vida por un temor arraigado,
    #     impidi√©ndote explorar nuevas oportunidades y experiencias enriquecedoras? Comparte tu profunda reflexi√≥n en
    #     los comentarios. Dale like a este video si crees firmemente en el poder de la preparaci√≥n activa y la
    #     confianza cultivada como la verdadera protecci√≥n contra los desaf√≠os de la vida, en lugar de la evitaci√≥n
    #     basada en el miedo, y s√≠gueme para explorar juntos m√°s analog√≠as reveladoras que iluminan la naturaleza del
    #     temor y el camino hacia la liberaci√≥n.""",
    #     "style_tags": "(calm) (narrator)"
    # },
    # "ENRIQUE": {
    #     "temp": 0.65,
    #     "top_p": 0.70,
    #     "chunk": 300,
    #     "penalty": 1.035,
    #     "ref_path": str(PROJECT_ROOT / "voices" / "Elevenlabs_Enrique_Nieto.wav"),
    #     "prompt": """El agua, la confianza y el miedo. Una lecci√≥n poderosa y reveladora sobre la verdadera
    #     protecci√≥n y el poder de la preparaci√≥n. Considera la profunda ense√±anza que subyace a la instrucci√≥n sobre
    #     el miedo al agua.
    #
    #     Inbuir en la mente de un ni√±o peque√±o un temor paralizante hacia la profundidad, creyendo err√≥neamente que
    #     as√≠ se le protege de un posible ahogamiento, puede parad√≥jicamente paralizarlo por completo en un momento de
    #     peligro real, impidi√©ndole reaccionar de manera efectiva para salvar su propia vida. En contraste,
    #     ense√±ar al ni√±o un amor genuino por el agua como una parte esencial y maravillosa de la naturaleza,
    #     inculcarle un respeto saludable por su poder y, lo que es crucial, dotarlo de la habilidad vital de nadar con
    #     confianza, empodera al ni√±o de una manera transformadora. Esta analog√≠a poderosa se extiende a innumerables
    #     otros temores que, con las mejores intenciones pero con resultados a menudo limitantes, se nos transmiten
    #     desde la infancia.
    #
    #     ¬øCu√°les son esas aguas profundas metaf√≥ricas que has estado evitando en tu vida por un temor arraigado,
    #     impidi√©ndote explorar nuevas oportunidades y experiencias enriquecedoras? Comparte tu profunda reflexi√≥n en
    #     los comentarios. Dale like a este video si crees firmemente en el poder de la preparaci√≥n activa y la
    #     confianza cultivada como la verdadera protecci√≥n contra los desaf√≠os de la vida, en lugar de la evitaci√≥n
    #     basada en el miedo, y s√≠gueme para explorar juntos m√°s analog√≠as reveladoras que iluminan la naturaleza del
    #     temor y el camino hacia la liberaci√≥n.""",
    #     "style_tags": "(calm) (narrator)"
    # }
}

# Platform detection
is_windows = platform.system() == "Windows"
should_compile = False if is_windows else True


class FishTotalLab:
    def __init__(self, checkpoint_path=None):
        """
        Initializes the S1-Mini engine with memory safeguards.
        """
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.vocal_dna_cache = {}  # Cache for encoded references

        # Default path to the S1-Mini model (~3.36 GB)
        self.checkpoint_dir = checkpoint_path or (PROJECT_ROOT / "checkpoints" / "openaudio-s1-mini")

        # Use half precision (FP16) for speed and memory efficiency
        self.precision = torch.half

        # Compile only on Linux (Kaggle), disable on Windows to avoid errors
        self.should_compile = False if platform.system() == "Windows" else True

        logger.info(f"üöÄ Initializing S1-Mini Engine | Device: {self.device} | Compile: {self.should_compile}")

        try:
            self.engine = self._load_models()
            logger.success("‚úÖ Models loaded successfully.")
        except Exception as e:
            logger.error(f"‚ùå Failed to load models: {e}")
            raise e

        torch.cuda.empty_cache()
        gc.collect()

    def _load_models(self):
        """Loads the Llama queue and VQ-GAN Decoder."""
        llama_queue = launch_thread_safe_queue(
            checkpoint_path=self.checkpoint_dir,
            device=self.device,
            precision=self.precision,
            compile=self.should_compile
        )
        decoder_model = load_decoder_model(
            config_name="modded_dac_vq",
            checkpoint_path=self.checkpoint_dir / "codec.pth",
            device=self.device
        )
        return TTSInferenceEngine(
            llama_queue=llama_queue,
            decoder_model=decoder_model,
            precision=self.precision,
            compile=self.should_compile
        )

    def clean_text(self, text):
        """Sanitizes input text."""
        if not text: return ""
        text = re.sub(r'([.!?‚Ä¶])(?=\S)', r'\1 ', text)
        text = text.replace("\n", " ").replace("\t", " ")
        return re.sub(r'\s+', ' ', text).strip()

    def split_text(self, text, max_chars=200):
        """
        HYBRID SPLIT STRATEGY (PARAGRAPHS + FATIGUE CONTROL):

        1. Primary Logic: Split by visual paragraphs (double newlines).
        2. Secondary Logic (Fatigue Check): If a paragraph is longer than 'max_chars'
           (e.g., 400), it forces an internal split by sentences.

        Why?
        Long text blocks cause 'Style Drift' (loss of tone) and hallucinations
        at the end. By forcing a split on long paragraphs, we refresh the
        style tags "(calm) (deep voice)" more frequently, keeping the voice stable.

        Args:
            text (str): Input text.
            max_chars (int): The safety limit. If a paragraph exceeds this,
                             it gets chopped. Recommended: 400-450.
        """
        # Clean up input text
        text = self.clean_text(text)
        sentences = re.split(r'(?<=[.!?‚Ä¶])\s+', text)
        chunks = []
        current_chunk = ""
        for sentence in sentences:
            if not sentence.strip(): continue
            if len(current_chunk) + len(sentence) < max_chars:
                current_chunk += sentence + " "
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + " "
        if current_chunk:
            chunks.append(current_chunk.strip())
        return chunks

    def _crossfade_chunks(self, audio_list, crossfade_ms=30, sample_rate=44100):
        """
        Merges audio chunks using a linear crossfade to eliminate robotic clicks.
        """
        if not audio_list: return None
        if len(audio_list) == 1: return audio_list[0]
        fade_samples = int(sample_rate * crossfade_ms / 1000)
        combined = audio_list[0]
        for next_chunk in audio_list[1:]:
            if len(combined) < fade_samples or len(next_chunk) < fade_samples:
                combined = np.concatenate((combined, next_chunk))
                continue
            fade_out = np.linspace(1, 0, fade_samples)
            fade_in = np.linspace(0, 1, fade_samples)
            tail = combined[-fade_samples:] * fade_out
            head = next_chunk[:fade_samples] * fade_in
            overlap = tail + head
            combined = np.concatenate((combined[:-fade_samples], overlap, next_chunk[fade_samples:]))
        return combined

    def _normalize_audio(self, audio_data, target_db=-1.0):
        max_val = np.abs(audio_data).max()
        if max_val == 0: return audio_data
        target_amp = 10 ** (target_db / 20)
        return audio_data * (target_amp / max_val)

    def _load_and_trim_audio(self, file_path, max_duration=60):
        """
        Carga y recorta el audio autom√°ticamente si es muy largo para salvar la VRAM.
        """
        try:
            data, sr = sf.read(file_path)

            if len(data) > sr * max_duration:
                logger.warning(
                    f"‚úÇÔ∏è Audio too long ({len(data) / sr:.1f}s). Trimming to {max_duration}s to prevent OOM.")
                data = data[:int(sr * max_duration)]

            buffer = io.BytesIO()
            sf.write(buffer, data, sr, format='WAV')
            return buffer.getvalue()

        except Exception as e:
            logger.error(f"Error loading audio {file_path}: {e}")
            with open(file_path, "rb") as f:
                return f.read()

    def generate_audio_for_params(self, voice_key, raw_text, temp, top_p, penalty, chunk_size, style_tags, seed_base: int = 1234):
        """
        Main API method. Optimized for stability using presets.
        """
        if voice_key not in VOICE_PRESETS:
            logger.error(f"‚ùå Voice key '{voice_key}' not found.")
            return None, None

        # Load parameters from the preset
        params = VOICE_PRESETS[voice_key]
        set_seed(seed_base)

        # --- 1. Vocal DNA Caching (Load Reference) ---
        cache_key = (voice_key, params["ref_path"])
        if cache_key in self.vocal_dna_cache:
            audio_bytes = self.vocal_dna_cache[cache_key]
        else:
            audio_bytes = self._load_and_trim_audio(params["ref_path"], max_duration=60)
            self.vocal_dna_cache[cache_key] = audio_bytes

        # --- 2. Text Preparation ---
        # Clean and split text into manageable chunks (200 chars optimal)
        text_chunks = self.split_text(raw_text, max_chars=200)

        raw_audio_segments = []
        hist_tokens = None
        hist_text = None

        # Determine tags
        current_tags = style_tags if style_tags else params.get("style_tags", "")


        try:
            for i, chunk_text in enumerate(text_chunks):
                chunk_text = chunk_text.strip()
                if not chunk_text: continue

                logger.debug(f"‚è≥ Processing chunk {i + 1}/{len(text_chunks)}")

                # --- Strategy: Initial Tag Injection Only ---
                # Inject tags only on the first chunk to set the tone, then rely on context.
                # If you prefer constant injection, remove the 'if i == 0 else chunk_text' logic.
                processed_text = f"{current_tags} {chunk_text}" if (i == 0 and current_tags) else chunk_text
                #processed_text = f"{chunk_text}"

                # --- Auto-Retry Mechanism (The Judge) ---
                max_retries = 3
                best_attempt = None

                for attempt in range(max_retries):
                    # Slight seed variation for retries
                    if attempt > 0:
                        set_seed(seed_base + i + attempt * 100)

                    req = ServeTTSRequest(
                        text=processed_text,
                        references=[ServeReferenceAudio(audio=audio_bytes,
                                                        text=params["prompt"]
                                                        )],
                        use_memory_cache="on",
                        chunk_length=params['chunk'],  # Use chunk size from preset (e.g., 300)
                        max_new_tokens=1024,  # Large buffer to prevent cuts
                        top_p=params['top_p'],
                        temperature=params['temp'],
                        repetition_penalty=params['penalty'],
                        format="wav",
                        prompt_text=[hist_text] if hist_text is not None else None,
                        prompt_tokens=[hist_tokens] if hist_tokens is not None else None
                    )

                    # req = ServeTTSRequest(
                    #     text=processed_text,
                    #     references=[ServeReferenceAudio(
                    #         audio=audio_bytes,
                    #         text=params["prompt"]
                    #     )],
                    #     # Opcional: Si quieres que recuerde cach√©s anteriores para ir m√°s r√°pido, d√©jalo "on".
                    #     # El default es "off", pero "on" no afecta la calidad, solo la velocidad.
                    #     use_memory_cache="on",
                    #
                    #     # IMPORTANTE: Si est√°s pasando historial (contexto previo), d√©jalo.
                    #     # Si quieres una prueba 100% limpia desde cero, borra estas dos l√≠neas tambi√©n.
                    #     # prompt_text=[hist_text] if hist_text is not None else None,
                    #     # prompt_tokens=[hist_tokens] if hist_tokens is not None else None
                    # )

                    final_res = None
                    for res in self.engine.inference(req):
                        if res.code == "final":
                            final_res = res
                            break

                    # --- Quality Check ---
                    if final_res and final_res.codes is not None:
                        num_tokens = final_res.codes.shape[1]

                        # Rule: Minimum 1 token per character (approx).
                        # Adjust based on language speed. Spanish usually ~1.2-1.4 tokens/char.
                        min_tokens_needed = len(chunk_text)

                        if num_tokens < min_tokens_needed:
                            logger.warning(f"‚ö†Ô∏è Chunk too short ({num_tokens} vs {len(chunk_text)} chars). Retrying...")
                            continue

                        best_attempt = final_res
                        break

                # If all retries fail, use the last result
                if best_attempt is None and final_res is not None:
                    logger.error(f"‚ùå Retries failed for chunk {i}. Using fallback.")
                    best_attempt = final_res

                if best_attempt is None or best_attempt.audio is None:
                    continue

                sr, audio_np = best_attempt.audio

                # Append audio segment
                padding_samples = int(sr * 0.25)
                silence_pad = np.zeros(padding_samples, dtype=audio_np.dtype)
                audio_padded = np.concatenate((audio_np, silence_pad))
                raw_audio_segments.append(audio_padded)

                # --- Context Update (Short Memory) ---
                # Keep only 50 tokens to maintain flow but prevent artifact accumulation (robotic voice)
                if best_attempt.codes is not None:
                    codes = torch.from_numpy(best_attempt.codes).to(torch.int)
                    keep = 50
                    if codes.shape[1] > keep:
                        codes = codes[:, -keep:]
                    hist_tokens = codes
                    hist_text = chunk_text

                # Clean VRAM
                torch.cuda.empty_cache()
                gc.collect()

            # --- 3. Post-Processing ---
            if raw_audio_segments:
                logger.info("üîß Applying Crossfade and Normalization...")

                # Apply Crossfade (30ms for smoother transitions)
                merged = self._crossfade_chunks(raw_audio_segments, crossfade_ms=30)

                # Normalize
                final_audio = self._normalize_audio(merged)

                # Optional: Add silence padding at the end
                silence_pad = np.zeros(int(44100 * 0.5))
                final_audio = np.concatenate((final_audio, silence_pad))

                return final_audio, 44100

            return None, None

        except Exception as e:
            logger.error(f"üî• Engine Error: {e}")
            import traceback
            traceback.print_exc()
            return None, None

    def run_hyper_search(self, text, num_tests=5):
        logger.info(f"üß™ Starting Hyper-Search for {len(VOICE_PRESETS)} voices.")
        timestamp = datetime.now().strftime("%H%M%S")

        for voice_name, base_params in VOICE_PRESETS.items():
            voice_folder = PROJECT_ROOT / f"LAB_{voice_name}_{timestamp}"
            voice_folder.mkdir(parents=True, exist_ok=True)
            logger.info(f"üî¨ Testing Voice: {voice_name}")

            for i in range(num_tests):
                curr_temp = base_params['temp']
                curr_pen = base_params['penalty']
                curr_chunk = base_params['chunk']

                logger.trace(f"üåÄ Test {i + 1}: Chunk Size={curr_chunk} | (T={curr_temp}, P={curr_pen})")

                result_tuple = self.generate_audio_for_params(
                    voice_name,
                    text,
                    temp=curr_temp,
                    top_p=base_params['top_p'],
                    penalty=curr_pen,
                    chunk_size=curr_chunk,
                    style_tags=base_params.get("style_tags", "")
                )

                if result_tuple is not None and result_tuple[0] is not None:
                    audio, sample_rate = result_tuple
                    filename = f"{voice_name}_FinalFixed_{timestamp}.wav"
                    sf.write(str(voice_folder / filename), audio, sample_rate, subtype="PCM_16")
                    logger.success(f"üì¶ Audio Successful Generated: {filename}")

            shutil.make_archive(str(PROJECT_ROOT / f"RESULTS_{voice_name}_{timestamp}"), 'zip', voice_folder)
            logger.success(f"üì¶ Test pack created for {voice_name}")

    # def run_hyper_search(self, text, num_tests=1):
    #     """
    #     LABORATORIO MATRICIAL:
    #     Itera sobre Rango de Temperaturas x Variaciones de Tags.
    #     """
    #     logger.info(f"üß™ Starting Hyper-Search for {len(VOICE_PRESETS)} voices.")
    #     timestamp = datetime.now().strftime("%H%M%S")
    #
    #     # --- üéõÔ∏è CONFIGURACI√ìN DEL LABORATORIO ---
    #     # 1. Barrido de Temperaturas (Estabilidad vs Creatividad)
    #     test_temps = [0.65, 0.66, 0.67, 0.68, 0.69, 0.70]
    #
    #     # 2. Par√°metros Fijos (Ganadores)
    #     fixed_top_p = 0.70
    #     fixed_penalty = 1.035
    #
    #     # 3. Variaciones de Tags a probar por cada temperatura
    #     tag_variations = [
    #         "(calm)",
    #         "(calm) (narrator)",
    #         "(narrator)",
    #         "(calm) (narrator) (deep voice)"
    #     ]
    #     # ------------------------------------------
    #
    #     for voice_name, base_params in VOICE_PRESETS.items():
    #         if voice_name != "CAMILA": continue
    #
    #         voice_folder = PROJECT_ROOT / f"LAB_{voice_name}_{timestamp}"
    #         voice_folder.mkdir(parents=True, exist_ok=True)
    #         logger.info(f"üî¨ Testing Voice: {voice_name}")
    #
    #         # Bucle 1: Temperaturas
    #         for curr_temp in test_temps:
    #
    #             # Bucle 2: Variaciones de Tags
    #             for i, current_tags in enumerate(tag_variations):
    #                 curr_chunk = base_params['chunk']
    #
    #                 # Crear nombre limpio para el archivo (ej: calm_narrator)
    #                 tag_suffix = current_tags.replace("(", "").replace(")", "").replace(" ", "_").strip("_")
    #
    #                 logger.trace(f"üåÄ Test T={curr_temp} | Tags='{current_tags}'")
    #
    #                 result_tuple = self.generate_audio_for_params(
    #                     voice_name,
    #                     text,
    #                     temp=curr_temp,
    #                     top_p=fixed_top_p,
    #                     penalty=fixed_penalty,
    #                     chunk_size=curr_chunk,
    #                     style_tags=current_tags,
    #                     seed_base=1234 + i  # Variar semilla ligeramente por cada tag
    #                 )
    #
    #                 if result_tuple is not None and result_tuple[0] is not None:
    #                     audio, sample_rate = result_tuple
    #
    #                     # Nombre descriptivo: CAMILA_T0.65_calm_narrator.wav
    #                     filename = f"{voice_name}_T{curr_temp}_{tag_suffix}_{timestamp}.wav"
    #
    #                     sf.write(str(voice_folder / filename), audio, sample_rate, subtype="PCM_16")
    #                     logger.success(f"üì¶ Generated: {filename}")
    #
    #         shutil.make_archive(str(PROJECT_ROOT / f"RESULTS_{voice_name}_{timestamp}"), 'zip', voice_folder)
    #         logger.success(f"üì¶ ZIP ready for {voice_name}")


if __name__ == "__main__":
    lab = FishTotalLab()

    # TEXTO DE PRUEBA
    LONG_CHAPTER = """
            Todos venimos de un mismo campo fuente, de una misma gran energ√≠a, de un mismo Dios, de un mismo
            universo, como le quieras llamar. Todos somos parte de eso. Nacemos y nos convertimos en esto por un ratito,
            muy chiquito, muy chiquitito, que creemos que es muy largo y se nos olvida que vamos a regresar a ese lugar
            de donde venimos.

            Escucha bien esto. No eres una gota en el oc√©ano, eres el oc√©ano entero en una gota. Tu imaginaci√≥n no es un estado
            de fantas√≠a o ilusi√≥n, es la verdadera realidad esperando ser reconocida. Cuando cierras los ojos y asumes el
            sentimiento de tu deseo cumplido, no est√°s "fingiendo", est√°s accediendo a la cuarta dimensi√≥n, al mundo de las
            causas, donde todo ya existe. Lo que ves afuera, en tu mundo f√≠sico, es simplemente una pantalla retrasada, un
            eco de lo que fuiste ayer, de lo que pensaste ayer.

            Si tu realidad actual no te gusta, deja de pelear con la pantalla. No puedes peinar tu reflejo en el espejo,
            tienes que peinarte t√∫. Debes cambiar la concepci√≥n que tienes de ti mismo. Preg√∫ntate: ¬øQui√©n soy yo ahora?
            Si la respuesta no es "Soy pr√≥spero", "Soy amado", "Soy saludable", entonces est√°s usando tu poder divino en tu
            contra. El universo no te juzga, simplemente te dice "S√ç". Si dices "estoy arruinado", el universo dice "S√ç, lo est√°s".
            Si dices "Soy abundante", el universo dice "S√ç, lo eres".

            Por lo tanto, el secreto no es el esfuerzo f√≠sico ni la lucha externa. El secreto es el cambio interno de estado.
            Moverte, en tu mente, del estado de carencia al estado de posesi√≥n. Sentir la textura de la realidad que deseas
            hasta que sea tan natural que ya no la busques, porque sabes que ya la tienes. Y cuando esa certeza interna hace
            clic, el mundo exterior no tiene m√°s remedio que reorganizarse para reflejar tu nueva verdad. E inevitablemente,
            vas a regresar a tu poder.
        """

    LONG_CHAPTER_2 = """
            Imagina por un momento que no eres simplemente un cuerpo f√≠sico luchando en el espacio, sino una frecuencia vibratoria, 
            una extensi√≥n directa de la inteligencia infinita. Nunca has estado separado de la totalidad. Esa sensaci√≥n de soledad 
            es solo una ilusi√≥n √≥ptica de la mente, un olvido temporal de tu verdadera naturaleza ilimitada y eterna que siempre 
            est√° conectada a la fuente.

            Entiende bien esto. El tiempo no es una l√≠nea recta hacia el futuro, es un vasto oc√©ano de posibilidades ocurriendo ahora mismo. 
            Tu deseo no est√° en un "ma√±ana" lejano esperando ser alcanzado; est√° aqu√≠, en una frecuencia paralela que a√∫n no has 
            sintonizado. Al igual que una radio no crea la m√∫sica, t√∫ no "creas" tu realidad desde la nada, simplemente sintonizas 
            la versi√≥n de ti mismo que ya la est√° viviendo. La realidad f√≠sica es solo el residuo de tus frecuencias pasadas.

            Si sigues observando lo que te falta, est√°s perpetuando la escasez. La realidad es arcilla fresca en manos de tu consciencia. 
            No puedes moldear una nueva figura si sigues aferrado a la forma antigua. Preg√∫ntate: ¬øQu√© sentir√≠a si mi deseo ya fuera un hecho? 
            El universo no entiende de s√∫plicas, entiende de resonancia. Si vibras en "necesidad", atraer√°s m√°s necesidad. 
            Si vibras en "gratitud", atraer√°s motivos infinitos para agradecer.

            As√≠ pues, la maestr√≠a no reside en manipular el mundo externo, sino en conquistar tu di√°logo interno. Se trata de 
            habitar el estado del deseo cumplido con tanta convicci√≥n que la evidencia f√≠sica se vuelva irrelevante. Camina con 
            la certeza absoluta de quien ya posee el tesoro. Cuando esa paz inquebrantable se instala en tu pecho, el mundo f√≠sico 
            no tiene otra opci√≥n que ceder y moldearse a tu nueva frecuencia... Inevitablemente, te convertir√°s en lo que sientes que eres.
        """

    lab.run_hyper_search(LONG_CHAPTER_2, num_tests=1)